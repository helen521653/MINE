{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd864d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.special import digamma\n",
    "from sklearn.neighbors import BallTree, KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ce0c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6354cd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_metric_tree_types = {\"kd_tree\": KDTree, \"ball_tree\": BallTree}\n",
    "\n",
    "class KSG:\n",
    "    def __init__(self, k_neighbors=3, tree_type=\"kd_tree\"):\n",
    "        self.k_neighbours, self.tree_type = k_neighbors, tree_type\n",
    "\n",
    "    def _tree(self, data):\n",
    "        return _metric_tree_types[self.tree_type](data, metric=\"chebyshev\")\n",
    "\n",
    "    def __call__(self, x, y, std=False):\n",
    "        n_samples, k_neighbours = x.shape[0], min(self.k_neighbours, x.shape[0] - 1)\n",
    "        x, y = x.reshape(n_samples, -1), y.reshape(n_samples, -1)\n",
    "        xy = np.concatenate([x, y], axis=-1)\n",
    "\n",
    "        xt, yt, xyt = self._tree(x), self._tree(y), self._tree(xy)\n",
    "        distances, _ = xyt.query(xy, k=k_neighbours + 1)\n",
    "        distances = distances[:, k_neighbours] - 1e-15\n",
    "        nx = xt.query_radius(x, distances, count_only=True)\n",
    "        ny = yt.query_radius(y, distances, count_only=True)\n",
    "\n",
    "        vals = digamma(nx) + digamma(ny)\n",
    "        mi = max(0.0, digamma(k_neighbours) + digamma(n_samples) - np.mean(vals))\n",
    "        return (mi, np.std(vals) / math.sqrt(n_samples)) if std else mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf1767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_orthonormal_matrices_torch(d, k, batch, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Return tensor of shape (batch, d, k) with orthonormal columns for each element (Haar).\n",
    "    Uses batched QR.\n",
    "    \"\"\"\n",
    "    A = torch.randn((batch, d, k), device=device, dtype=torch.float32)\n",
    "    Q, R = torch.linalg.qr(A)  # Q: (batch,d,k), R: (batch,k,k)\n",
    "    diag = torch.sign(torch.diagonal(R, dim1=-2, dim2=-1))  # (batch, k)\n",
    "    diag[diag == 0] = 1.0\n",
    "    Q = Q * diag.unsqueeze(1)  # broadcast -> (batch, d, k)\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6300c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whiten_torch(X, eps=1e-6, device=DEVICE):\n",
    "    \"\"\"\n",
    "    PCA-whitening on device (torch). Returns tensor (n, d) on device.\n",
    "    Accepts numpy arrays or torch tensors.\n",
    "    \"\"\"\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = torch.from_numpy(X).to(dtype=torch.float32, device=device)\n",
    "    else:\n",
    "        X = X.to(dtype=torch.float32, device=device)\n",
    "\n",
    "    Xc = X - X.mean(dim=0, keepdim=True)\n",
    "    n = Xc.shape[0]\n",
    "    cov = (Xc.t() @ Xc) / (n - 1)  # (d, d)\n",
    "\n",
    "    # SVD (stable on symmetric matrices)\n",
    "    U, S, Vh = torch.linalg.svd(cov)  # S shape (d,)\n",
    "    inv_sqrt = torch.diag(1.0 / torch.sqrt(S + eps))\n",
    "    W = U @ inv_sqrt @ U.t()\n",
    "    Xw = Xc @ W\n",
    "    return Xw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbb9574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_projection_matrices(dX, dY, proj_k, n_proj, device=DEVICE, seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "    U_list = random_orthonormal_matrices_torch(dX, proj_k, n_proj, device=device)  # (n_proj,dX,k)\n",
    "    V_list = random_orthonormal_matrices_torch(dY, proj_k, n_proj, device=device)  # (n_proj,dY,k)\n",
    "    return U_list, V_list\n",
    "\n",
    "def sliced_mi_with_fixed_proj(X_np, Y_np, U_list, V_list, knn=5, device=DEVICE):\n",
    "    Xw = whiten_torch(X_np, device=device)\n",
    "    Yw = whiten_torch(Y_np, device=device)\n",
    "    n_proj = U_list.shape[0]\n",
    "    proj_k = U_list.shape[-1]\n",
    "\n",
    "    X_proj_batch = torch.einsum('nd,bdk->bnk', Xw, U_list)  # (n_proj, n, k)\n",
    "    Y_proj_batch = torch.einsum('nd,bdk->bnk', Yw, V_list)\n",
    "\n",
    "    X_cpu = X_proj_batch.detach().cpu().numpy()\n",
    "    Y_cpu = Y_proj_batch.detach().cpu().numpy()\n",
    "\n",
    "    ksg = KSG(k_neighbors=knn)\n",
    "    mis = [float(ksg(X_cpu[i], Y_cpu[i])) for i in range(n_proj)]\n",
    "    mis = np.array(mis)\n",
    "    return mis.mean(), mis.std() / np.sqrt(len(mis)), mis  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd50d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_two_datasets(X1, Y1, X2, Y2, proj_k=2, n_proj=500, knn=3, seed=0):\n",
    "    dX, dY = X1.shape[1], Y1.shape[1]\n",
    "    U_list, V_list = make_projection_matrices(dX, dY, proj_k, n_proj, seed=seed, device=DEVICE)\n",
    "\n",
    "    mean1, se1, mis1 = sliced_mi_with_fixed_proj(X1, Y1, U_list, V_list, knn=knn)\n",
    "    mean2, se2, mis2 = sliced_mi_with_fixed_proj(X2, Y2, U_list, V_list, knn=knn)\n",
    "\n",
    "    print(f\"Dataset A: {mean1:.4f} ± {se1:.4f}\")\n",
    "    print(f\"Dataset B: {mean2:.4f} ± {se2:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.hist(mis1, bins=30, alpha=0.5, label='Dataset A')\n",
    "    plt.hist(mis2, bins=30, alpha=0.5, label='Dataset B')\n",
    "    plt.axvline(mean1, color='blue', linestyle='--')\n",
    "    plt.axvline(mean2, color='orange', linestyle='--')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Sliced MI\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(\"Distribution of Sliced MI across projections\")\n",
    "    plt.show()\n",
    "\n",
    "    return (mean1, se1, mis1), (mean2, se2, mis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09355bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dim, Y_dim = 15, 20 \n",
    "n_samples = 1000\n",
    "\n",
    "# Dataset A\n",
    "dist1 = CorrelatedNormal(1.0, X_dim, Y_dim)\n",
    "X1, Y1 = dist1.rvs(n_samples)\n",
    "\n",
    "# Dataset B\n",
    "dist2 = CorrelatedNormal(2.0, X_dim, Y_dim)\n",
    "X2, Y2 = dist2.rvs(n_samples)\n",
    "\n",
    "\n",
    "resA, resB = compare_two_datasets(X1, Y1, X2, Y2, proj_k=2, n_proj=1000, knn=3, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843595db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
